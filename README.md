*Tags: Databricks, data engineering, python, SparkSQL*
**Description:**
- Engineered data pipelines for fire calls and text messages in Databricks environment: from raw data stored on an AWS S3 and PostgreSQL JDBC to become machine learning models saved on the cloud and ready to be used on new data.
- Created a database and its tables on Hadoop Distributed File System (HDFS), using techniques such as parallel reads, predicate push down, file formats and schemas support to accelerate data loading speed. 
- Improved programs performance on a cluster of nodes by analyzing Spark UI and performing partition, cache, and broadcast settings
- Tools used: *databricks, dbutils, AWS S3, sparkSQL, python, pyspark, numpy, pandas, sklearn, mlflow*

**Notebooks:**